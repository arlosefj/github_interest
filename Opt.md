quantize
https://github.com/eladhoffer/quantized.pytorch
ä½¿ç”¨pytorch

æˆ‘ä»¬çœŸçš„éœ€è¦æ¨¡å‹å‹ç¼©å—ï¼Ÿ
http://mitchgordon.me/machine/learning/2020/01/13/do-we-really-need-model-compression.html

### [ECCV 2018] PyTorch implementation for AMC: AutoML for Model Compression and Acceleration on Mobile Devices.
https://github.com/mit-han-lab/amc

ç¥ç»ç½‘ç»œé‡åŒ–ç›¸å…³æ–‡çŒ®é›†
https://github.com/xu3kev/neural-networks-quantization-notes

Pytorch Implementation of Neural Architecture Optimization
https://github.com/renqianluo/NAO_pytorch

XNNPACKï¼šé¢å‘æ‰‹æœºå’Œæµè§ˆå™¨çš„é«˜æ•ˆæµ®ç‚¹ç¥ç»ç½‘ç»œæ¨ç†è¿ç®—å™¨
https://github.com/google/XNNPACK

TensorRT æ·±åº¦å­¦ä¹ ä¼˜åŒ–
https://github.com/ardianumam/Tensorflow-TensorRT

prune
https://github.com/jacobgil/pytorch-pruning
https://jacobgil.github.io/deeplearning/pruning-deep-learning
2016å¹´çš„ç®—æ³•

https://github.com/Eric-mingjie/rethinking-network-pruning
æä¾›äº†6ç§ç½‘ç»œå‰ªææ–¹æ³•ï¼Œä½¿ç”¨pytorch
https://github.com/alexfjw/prunnable-layers-pytorch

ã€ç”¨TensorRTç½‘ç»œå®šä¹‰APIå®ç°æµè¡Œçš„æ·±åº¦å­¦ä¹ ç½‘ç»œã€‘
https://github.com/wang-xinyu/tensorrtx

ã€é‡åŒ–å™ªå£°è®­ç»ƒæé™æ¨¡å‹å‹ç¼©ã€‘
https://github.com/pytorch/fairseq/tree/master/examples/quant_noise

### (ç»¼è¿°)é¢å‘ç§»åŠ¨è®¾å¤‡/è¾¹ç¼˜è®¡ç®—çš„æ–°å‹ç¥ç»ç½‘ç»œæ¶æ„
https://machinethink.net/blog/mobile-architectures/

Pruning AI networks without impacting performance
https://github.com/DNNToolBox/Net-Trim-v1

åŸºäºKerasçš„AutoMLæœºå™¨å­¦ä¹ è‡ªåŠ¨åŒ–åº“
https://github.com/jhfjhfj1/autokeras

prune & quantize
https://github.com/NervanaSystems/distiller
intelå¼€æºçš„ç½‘ç»œè’¸é¦å·¥å…·ï¼Œä½¿ç”¨pytorchæ¡†æ¶ï¼Œä¸æ–­æ›´æ–°ä¸­ã€‚ã€‚ã€‚
æ•™ç¨‹ï¼šhttps://github.com/NervanaSystems/distiller/wiki/Tutorial:-Using-Distiller-to-prune-a-PyTorch-language-model

tencent
https://github.com/Tencent/PocketFlow

è‡ªåŠ¨åŒ–è¶…å‚æ•°æœç´¢ï¼Œåé¢å¯æ¥å¾ˆå¤šä¸åŒæ¡†æ¶
https://github.com/tobegit3hub/advisor

ç½‘ç»œç»“æ„æœç´¢ï¼Œè°·æ­Œå‡ºå“
https://github.com/tensorflow/adanet

Slimmable Neural Networks
https://github.com/JiahuiYu/slimmable_networks
https://github.com/JiahuiYu/slimmable_networks/tree/detection

Trained Rank Pruning for Efficient Deep Neural Networks
https://github.com/yuhuixu1993/Trained-Rank-Pruning

AutoMLç›¸å…³èµ„æºåˆ—è¡¨
https://github.com/dragen1860/awesome-AutoML

æ·±åº¦ç½‘ç»œæ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿç›¸å…³æ–‡çŒ®å¤§åˆ—è¡¨
https://github.com/sun254/awesome-model-compression-and-acceleration

è¶…å‚ä¼˜åŒ–æ¡†æ¶Optuna
https://github.com/pfnet/optuna

å¾®è½¯å‘å¸ƒçš„AutoMLå·¥å…·åŒ…(è‡ªåŠ¨ç½‘ç»œç»“æ„æœç´¢/è¶…å‚ä¼˜åŒ–)
https://github.com/Microsoft/nni
https://github.com/Microsoft/nni/blob/master/docs/GetStarted.md

Kerasæ¨¡å‹è¶…å‚è°ƒä¼˜å·¥å…·
https://github.com/autonomio/talos

ç¥ç»ç½‘ç»œæœºå™¨å­¦ä¹ è‡ªåŠ¨åŒ–æ¡†æ¶
https://github.com/CiscoAI/amla

PyTorch å®ç°çš„NEAT (NeuroEvolution of Augmenting Topologies)ç¥ç»è¿›åŒ–ç®—æ³•
https://github.com/uber-research/PyTorch-NEAT/

æ¨¡å‹è¶…å‚è‡ªåŠ¨æœç´¢å·¥å…·
https://github.com/NVIDIA/Milano

ç¥ç»ç½‘ç»œæ¨¡å‹é‡åŒ–æ–¹æ³•ç®€ä»‹
http://chenrudan.github.io/blog/2018/10/02/networkquantization.html

Rethinking the Value of Network Pruning
https://github.com/Eric-mingjie/rethinking-network-pruning

åœ¨çº¿è¶…å‚æ•°ä¼˜åŒ–å¹³å°Bender
https://github.com/Dreem-Organization/benderopt


Tensorflow Implementation of ChannelNets (NIPS18) https://arxiv.org/abs/1809.01330
https://github.com/HongyangGao/ChannelNets

Neural Architecture Optimization
https://github.com/renqianluo/NAO

AdaNet ç®€ä»‹ï¼šå¿«é€Ÿçµæ´»çš„ AutoMLï¼Œæä¾›å­¦ä¹ ä¿è¯
https://github.com/tensorflow/adanet
https://mp.weixin.qq.com/s?__biz=MzU1OTMyNDcxMQ==&mid=2247485095&idx=1&sn=990ca481921261e9ff5d850bd3753d6e&chksm=fc184defcb6fc4f986862449c630c80e9f285647a6bcac4a9e03c1108d11554a427d62da148e&scene=0&xtrack=1#rd

Sonnetæ˜¯ä¸ªåŸºäºTensorFlowçš„åº“ï¼Œå¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¤æ‚çš„ç¥ç»ç½‘ç»œã€‚è¯¥é¡¹ç›®ç”±Deepmindçš„Malcolm Reynoldsåˆ›å»ºã€‚
https://github.com/deepmind/sonnet

ç¥ç»ç½‘ç»œç®€åŒ–åº”ç”¨æ¡†æ¶
https://github.com/mindsdb/mindsdb

è…¾è®¯å‘å¸ƒçš„æ¨¡å‹å‹ç¼©è‡ªåŠ¨åŒ–(AutoMC)æ¡†æ¶
https://github.com/Tencent/PocketFlow

é¢å‘æ‰‹æœºä¼˜åŒ–çš„é‡åŒ–ç¥ç»ç½‘ç»œç®—å­åº“
https://github.com/pytorch/QNNPACK

NVIDIA TensorRTï¼šNVIDIA GPUå’Œæ·±åº¦å­¦ä¹ åŠ é€Ÿå™¨çš„C++é«˜æ€§èƒ½æ¨ç†åº“
https://github.com/NVIDIA/TensorRT

PeleeNet: An efficient DenseNet architecture for mobile devices
https://github.com/Robert-JunWang/PeleeNet

æ·±åº¦ç½‘ç»œå‹ç¼©/åŠ é€Ÿæœ€æ–°è¿›å±•åˆ—è¡¨
https://github.com/MingSun-Tse/EfficientDNNs

ç”¨äºå¯»æ‰¾å’Œåˆ†æç¥ç»ç½‘ç»œé‡è¦ç¥ç»å…ƒçš„å·¥å…·åŒ…
https://github.com/fdalvi/NeuroX

å¼€æº:Keras + Hyperoptæ–¹ä¾¿è¶…å‚ä¼˜åŒ–çš„ç®€å•å°è£…Hyperas
http://maxpumperla.com/hyperas/

PyTorchæœºå™¨å­¦ä¹ è‡ªåŠ¨åŒ–ï¼šè‡ªåŠ¨æ¡†æ¶æœç´¢ã€è¶…å‚ä¼˜åŒ–
https://github.com/automl/Auto-PyTorch

Tensorized Embedding Layers for Efficient Model Compression
https://github.com/KhrulkovV/tt-pytorch

### åŸºäºpytorchå®ç°æ¨¡å‹å‹ç¼©
https://github.com/666DZY666/model-compression

DeepSpeedï¼šå¾®è½¯çš„æ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“ï¼Œè®©åˆ†å¸ƒå¼è®­ç»ƒæ›´ç®€å•ã€æ›´é«˜æ•ˆã€æ›´æœ‰æ•ˆ
https://github.com/microsoft/DeepSpeed
https://github.com/microsoft/DeepSpeedExamples

Adlikï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹ç«¯åˆ°ç«¯ä¼˜åŒ–æ¡†æ¶ï¼Œå…¶æ¨¡å‹ç¼–è¯‘å™¨æ”¯æŒå‰ªæã€é‡åŒ–å’Œç»“æ„å‹ç¼©ç­‰å¤šç§ä¼˜åŒ–æŠ€æœ¯ï¼Œå¯ä»¥æ–¹ä¾¿åœ°ç”¨äºä½¿ç”¨ TensorFlowã€ Kerasã€ PyTorch ç­‰å¼€å‘çš„æ¨¡å‹ï¼ŒæœåŠ¡å¹³å°æä¾›åŸºäºéƒ¨ç½²ç¯å¢ƒçš„å…·æœ‰ä¼˜åŒ–è¿è¡Œæ—¶çš„æ·±åº¦å­¦ä¹ æ¨¡å‹
https://github.com/Adlik/Adlik

Code for paper "Learning to Reweight Examples for Robust Deep Learning"
https://github.com/uber-research/learning-to-reweight-examples

Code for â€œDiscrimination-aware-Channel-Pruning-for-Deep-Neural-Networksâ€
https://github.com/SCUT-AILab/DCP

ZeroQ: A Novel Zero Shot Quantization Framework
https://github.com/amirgholami/ZeroQ

Graph Transforms to Quantize and Retrain Deep Neural Nets in TensorFlow. https://arxiv.org/abs/1903.08066
https://github.com/Xilinx/graffitist

A PyTorch implementation of "Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights"
https://github.com/Mxbonn/INQ-pytorch

This repository contains the training code of Quantization Networks introduced in our CVPR 2019 paper: Quantization Networks.
https://github.com/aliyun/alibabacloud-quantization-networks

Code released for "FNNP: Fast Neural Network Pruning Using Adaptive Batch Normalization"
https://github.com/anonymous47823493/FNNP

Code for the NuerIPS'19 paper "Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks"
https://github.com/youzhonghui/gate-decorator-pruning

ã€PyTorchå®ç°çš„æ·±åº¦æ¨¡å‹å‹ç¼©ã€‘
https://github.com/666DZY666/model-compression

ã€æ·±åº¦ç½‘ç»œå‹ç¼©æ–‡çŒ®/ä»£ç åˆ—è¡¨ã€‘
https://github.com/csyhhu/Awesome-Deep-Neural-Network-Compression

ã€æ¨¡å‹å‹ç¼©ç›¸å…³æ–‡çŒ®èµ„æºå¤§åˆ—è¡¨ã€‘
https://github.com/ChanChiChoi/awesome-model-compression

ã€ç¥ç»ç½‘ç»œå‹ç¼©ä¸åŠ é€Ÿèµ„æºé›†é”¦ã€‘
https://github.com/mrgloom/Network-Speed-and-Compression

Neural Rejuvenation: Improving Deep Network Training by Enhancing Computational Resource Utilization at CVPR'19
https://github.com/joe-siyuan-qiao/NeuralRejuvenation-CVPR19

### é¢å‘ç›®æ ‡æ£€æµ‹/è¯­ä¹‰åˆ†å‰²çš„æœºå™¨å­¦ä¹ è‡ªåŠ¨åŒ–(AutoML)
https://github.com/NoamRosenberg/AutoML

ã€ç¥ç»ç½‘ç»œä¿®å‰ªæŠ€æœ¯ç ”ç©¶æŒ‡å—ã€‘
https://pan.baidu.com/s/1onGzAUw4pKrySM1uS1HTeg

æœºå™¨å­¦ä¹ æ¨¡å‹å‹ç¼©ç›¸å…³æ–‡çŒ®ã€å·¥å…·ã€å­¦ä¹ èµ„æ–™åˆ—è¡¨
https://github.com/cedrickchee/awesome-ml-model-compression

æ·±åº¦ç¥ç»ç½‘ç»œä¿®å‰ª
https://towardsdatascience.com/pruning-deep-neural-network-56cae1ec5505

é¢å‘å›¾åƒåˆ†ç±»å’Œæ£€æµ‹çš„ç¥ç»ç½‘ç»œå‹ç¼©
https://arxiv.org/abs/1907.05686 https://ai.facebook.com/blog/compressing-neural-networks-for-image-classification-and-detection/

Partial Channel Connections for Memory-Efficient Differentiable Architecture Search
https://github.com/yuhuixu1993/PC-DARTS

Code for: "And the bit goes down: Revisiting the quantization of neural networks"
https://github.com/facebookresearch/kill-the-bits

Implementation with latest PyTorch for multi-gpu DARTS https://arxiv.org/abs/1806.09055
https://github.com/alphadl/darts.pytorch1.1 https://github.com/quark0/darts

ç¥ç»ç½‘ç»œæ¶æ„æœç´¢ç›¸å…³èµ„æºå¤§åˆ—è¡¨
https://github.com/D-X-Y/awesome-NAS

ã€æ¨¡å‹æ€§èƒ½å·¥å…·åº“ï¼Œä¸ºè®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæ¨¡å‹æä¾›é«˜çº§é‡åŒ–å’Œå‹ç¼©æŠ€æœ¯ã€‘
https://github.com/quic/aimet

ã€ç”¨PyTorch&AutoTorchå®ç°çš„RegNetç¥ç»ç½‘ç»œæ¶æ„æœç´¢ã€‘
https://github.com/zhanghang1989/RegNet-Search-PyTorch

ã€ç¥ç»ç½‘ç»œçš„ä¿®å‰ªã€‘ã€ŠNeural Network Pruningã€‹
https://nathanhubens.github.io/posts/deep%20learning/2020/05/22/pruning.html

ã€æ·±åº¦å­¦ä¹ è¶…å‚ç®¡ç†å™¨
https://github.com/megvii-research/hpman

ã€æ¨¡å‹ä¼˜åŒ–åŸºç¡€ã€‘ã€ŠModel Optimization 101ã€‹
https://docs.google.com/presentation/d/1tCbwcls4c_Imx0tC3kOW3yINSIbcHuKgcHimCAT3B0Q/edit#slide=id.p

ã€PyTorchç¥ç»ç½‘ç»œå‹ç¼©æ¡†æ¶ã€‘
https://github.com/openvinotoolkit/nncf_pytorch

QToolï¼šç¥ç»ç½‘ç»œé‡åŒ–å·¥å…·ç®±
https://github.com/blueardour/model-quantization

Group Sparsity: The Hinge Between Filter Pruning and Decomposition for Network Compression. CVPR2020.
https://github.com/ofsoundof/group_sparsity

Lossless CNN Channel Pruning via Gradient Resetting and Convolutional Re-parameterization
https://github.com/DingXiaoH/ResRep

èµ°é©¬è§‚èŠ±AutoML - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/212512984

æ¨¡å‹é‡åŒ–è®ºæ–‡/æ–‡æ¡£/ä»£ç åˆ—è¡¨
https://github.com/htqin/awesome-model-quantization

### Permute, Quantize, and Fine-tune: Efficient Compression of Neural Networks
https://github.com/uber-research/permute-quantize-finetune 

Memory Optimization for Deep Networks
https://github.com/utsaslab/MONeT

å¿’ä¿®æ–¯ä¹‹èˆ¹å¯å‘ä¸‹çš„çŸ¥è¯†è’¸é¦æ–°æ€è·¯
https://weibo.com/ttarticle/p/show?id=2309404569773894664467#_0

IntelÂ® Low Precision Optimization Toolï¼šIntelä½ç²¾åº¦ä¼˜åŒ–å·¥å…·
https://github.com/intel/lpot

### micronetï¼šæ·±åº¦ç½‘ç»œæ¨¡å‹å‹ç¼©ä¸éƒ¨ç½²åº“
https://github.com/666DZY666/micronet

Using ideas from product quantization for state-of-the-art neural network compression.
https://github.com/uber-research/permute-quantize-finetune

A GPU algorithm for sparse matrix-matrix multiplication
https://github.com/oresths/tSparse

Parallel Hyperparameter Optimization in Python
https://github.com/ARM-software/mango

source code of the paper: Robust Quantization: One Model to Rule Them All
https://github.com/moranshkolnik/RobustQuantization

Code and checkpoints of compressed networks for the paper titled "HYDRA: Pruning Adversarially Robust Neural Networks" (NeurIPS 2020)
https://github.com/inspire-group/hydra

GPU implementation of Xnor network on inference level.
https://github.com/metcan/Binary-Convolutional-Neural-Network-Inference-on-GPU

### Towards Optimal Structured CNN Pruning via Generative Adversarial Learning(GAL)
https://github.com/ShaohuiLin/GAL

TensorRT implementation of "RepVGG: Making VGG-style ConvNets Great Again"
https://github.com/upczww/TensorRT-RepVGG

Pushing the Limit of Post-Training Quantization by Block Reconstruction
https://github.com/yhhhli/BRECQ

Sparsifyï¼šæ˜“ç”¨çš„autoMLç¥ç»ç½‘ç»œç¨€ç–åŒ–ä¼˜åŒ–æ¥å£
https://github.com/neuralmagic/sparsify

### DeepSparse Engineï¼šç”¨ç¨€ç–åŒ–æ¨¡å‹æä¾›å‰æ‰€æœªæœ‰æ€§èƒ½çš„CPUæ¨ç†å¼•æ“
https://github.com/neuralmagic/deepsparse

ç¥ç»ç½‘ç»œé‡åŒ–/ä½ä½å®šç‚¹è®­ç»ƒç¡¬ä»¶å‹å¥½ç®—æ³•è®¾è®¡ç›¸å…³èµ„æ–™é›†
https://github.com/A-suozhang/awesome-quantization-and-fixed-point-training

â€œæœºå™¨å­¦ä¹ ä¼˜åŒ–â€è¯¾ç¨‹èµ„æ–™
github.com/rishabhk108/AdvancedOptML

ã€Š BNN - BN = ? Training Binary Neural Networks without Batch Normalizationã€‹(CVPRW 2021) 
github.com/VITA-Group/BNN_NoBN

ã€ŠAngularGrad: A New Optimization Technique for Angular Convergence of Convolutional Neural Networksã€‹(2021) 
github.com/mhaut/AngularGrad

Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better
https://www.arxiv-vanity.com/papers/2106.08962

Forward æ·±åº¦å­¦ä¹ æ¨ç†åŠ é€Ÿæ¡†æ¶ - A library for high performance deep learning inference on NVIDIA GPUs.
github.com/Tencent/Forward

Tritonï¼šè®©æ²¡æœ‰CUDAç»éªŒçš„ç ”ç©¶äººå‘˜ç¼–å†™é«˜æ•ˆçš„GPUä»£ç 
github.com/openai/triton

mmsegmentation-distillerï¼šåŸºäºmmsegmentationçš„çŸ¥è¯†è’¸é¦å·¥å…·ç®±
github.com/pppppM/mmsegmentation-distiller

TorchDistillerï¼šçŸ¥è¯†è’¸é¦å¼€æºPyTorchä»£ç é›†ï¼Œç‰¹åˆ«é¢å‘æ„ŸçŸ¥ä»»åŠ¡ï¼ŒåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡ã€ç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²
github.com/irfanICMLL/TorchDistiller

ç”¨NVIDIAå¼€æºæ¨¡å—å®ç°åŠ é€ŸSE(3)-Transformerè®­ç»ƒï¼Œâ€œä½¿ç”¨å†…å­˜å°‘9xï¼Œé€Ÿåº¦æ¯”åŸºå‡†å®˜æ–¹å®ç°å¿«21xâ€
github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/DrugDiscovery/SE3Transformer

é¢å‘è®¡ç®—æœºè§†è§‰çŸ¥è¯†è’¸é¦æ–‡çŒ®é›†
github.com/lilujunai/Awesome-Knowledge-Distillation-for-CV

### DS-Net++: Dynamic Weight Slicing for Efficient Inference in CNNs and Transformers
github.com/changlin31/DS-Net

PP-LCNet: A Lightweight CPU Convolutional Neural Network
https://arxiv.org/abs/2109.15099

TinyNeuralNetworkï¼šé«˜æ•ˆã€æ˜“ç”¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©æ¡†æ¶ï¼ŒåŒ…å«æ¨¡å‹ç»“æ„æœç´¢ã€å‰ªæã€é‡åŒ–ã€æ¨¡å‹è½¬æ¢ç­‰åŠŸèƒ½
github.com/alibaba/TinyNeuralNetwork

Model Compression Research Packageï¼šç”¨äºç ”ç©¶ç¥ç»ç½‘ç»œå‹ç¼©å’ŒåŠ é€Ÿæ–¹æ³•çš„åº“
github.com/IntelLabs/Model-Compression-Research-Package 

åˆ©ç”¨æ•°æ®é›†è’¸é¦æ›´é«˜æ•ˆè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹
https://ai.googleblog.com/2021/12/training-machine-learning-models-more.html

IntelÂ® Neural Compressorï¼šè¿è¡Œåœ¨Intel CPU/GPUä¸Šçš„ç¥ç»ç½‘ç»œå‹ç¼©åº“
github.com/intel/neural-compressor 

pytorchè‡ªåŠ¨åŒ–æ¨¡å‹å‹ç¼©å·¥å…·åº“ - é’ˆå¯¹pytorchæ¨¡å‹çš„è‡ªåŠ¨åŒ–æ¨¡å‹ç»“æ„åˆ†æå’Œä¿®æ”¹å·¥å…·é›†ï¼ŒåŒ…å«è‡ªåŠ¨åˆ†ææ¨¡å‹ç»“æ„çš„æ¨¡å‹å‹ç¼©ç®—æ³•åº“
github.com/THU-MIG/torch-model-compression

### YOLOv5-Compression - YOLOv5 Series Multi-backbone(TPH-YOLOv5, Ghostnet, ShuffleNetv2, Mobilenetv3Small, EfficientNetLite, PP-LCNet, SwinTransformer YOLO), Module(CBAM, DCN), Pruning (EagleEye, Network Slimming) and Quantization (MQBench) Compression Tool Box.
github.com/Gumpest/YOLOv5-Multibackbone-Compression

OpenDeltaï¼šå‚æ•°é«˜æ•ˆè°ƒä¼˜å¼€æºæ¡†æ¶
github.com/thunlp/OpenDelta 

NNCFï¼šç¥ç»ç½‘ç»œå‹ç¼©æ¡†æ¶
github.com/openvinotoolkit/nncf

scs4onnxï¼šONNXæ¨¡å‹å‹ç¼©å·¥å…·
github.com/PINTO0309/scs4onnx

### é«˜æ•ˆæ·±åº¦å­¦ä¹ ï¼šæ·±åº¦å­¦ä¹ è¿‡ç¨‹åŠ é€ŸæŠ€å·§é›†
github.com/Mountchicken/Efficient-Deep-Learning

ATOM - Automated Tool for Optimized Modelling - A Python package for fast exploration of machine learning pipelinesâ€™
github.com/tvdboom/ATOM 

ã€æ¨¡å‹é‡åŒ–è®ºæ–‡/æ–‡æ¡£/ä»£ç åˆ—è¡¨ã€‘'Awesome Model Quantization - A list of papers, docs, codes about model quantization' by Haotong Qin GitHub: github.com/htqin/awesome-model-quantization 

ã€Model Compression Toolkit (MCT)ï¼šæ¨¡å‹å‹ç¼©å·¥å…·åŒ…ï¼Œç”¨äºåœ¨å—é™ç¡¬ä»¶ä¸‹é«˜æ•ˆä¼˜åŒ–ç¥ç»ç½‘ç»œæ¨¡å‹ã€‘â€™Model Compression Toolkit (MCT) - Model Compression Toolkit (MCT) is an open source project for neural network model optimization under efficient, constrained hardware.' by Sony GitHub: github.com/sony/model_optimization

ã€Awesome AutoDLï¼šæ·±åº¦å­¦ä¹ è‡ªåŠ¨åŒ–(ç¥ç»æ¶æ„æœç´¢å’Œè¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–)ç›¸å…³èµ„æºå¤§åˆ—è¡¨ã€‘â€™Awesome AutoDL - A curated list of automated deep learning (including neural architecture search and hyper-parameter optimization) resources.' by D-X-Y GitHub: github.com/D-X-Y/Awesome-AutoDL

### ã€VoltaMLï¼šç”¨äºåŠ é€Ÿæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è½»é‡å¼€æºåº“ï¼Œå¯ä¼˜åŒ–ã€ç¼–è¯‘å’Œéƒ¨ç½²æ¨¡å‹åˆ°ç›®æ ‡CPUå’ŒGPUè®¾å¤‡ï¼Œåªéœ€ä¸€è¡Œä»£ç ã€‘â€™Accelerating Huggingface Models using voltaML - VoltaML is a lightweight library to convert and run your ML/DL deep learning models in high performance inference runtimes like TensorRT, TorchScript, ONNX and TVM.' by VoltaML GitHub: github.com/VoltaML/voltaML

ã€ä¸€è¡Œä»£ç æé«˜Hugging Face Transformersæ€§èƒ½ã€‘ã€ŠBetterTransformer, Out of the Box Performance for Hugging Face Transformersã€‹by Younes Belkada medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2

ã€voltaML-fast-stable-diffusionï¼šä¸€è¡Œä»£ç åŠ é€ŸStable Diffusion(10x)çš„è½»é‡åº“ã€‘'voltaML-fast-stable-diffusion - Lightweight library to accelerate Stable-Diffusion, Dreambooth into fastest inference models with single line of code ğŸ”¥ ğŸ”¥' by VoltaML GitHub: github.com/VoltaML/voltaML-fast-stable-diffusion

ã€Intelå¹³å°åŠ é€Ÿç‰ˆHugging Face transformersæ‰©å±•å·¥å…·åŒ…ï¼Œåˆ©ç”¨Intelç¥ç»å‹ç¼©å™¨æä¾›çš„ä¸€å¥—ä¸°å¯Œçš„æ¨¡å‹å‹ç¼©æŠ€æœ¯: é‡åŒ–ã€å‰ªæã€è’¸é¦ç­‰ï¼Œæ˜¾è‘—æé«˜äº†è‹±ç‰¹å°”å¹³å°ä¸Šçš„æ¨ç†æ•ˆç‡ã€‘â€™IntelÂ® Extension for Transformers: Accelerating Transformer-based Models on Intel Platforms' by Intel GitHub: github.com/intel/intel-extension-for-transformers

ã€å¤§å‹ Transformer æ¨¡å‹æ¨ç†ä¼˜åŒ–ã€‘ã€ŠLarge Transformer Model Inference Optimization | Lil'Logã€‹ 
https://lilianweng.github.io/posts/2023-01-10-inference-optimization/

'mperf - é¢å‘ç§»åŠ¨/åµŒå…¥å¼å¹³å°çš„ç®—å­æ€§èƒ½è°ƒä¼˜å·¥å…·ç®±' MegEngine GitHub: github.com/MegEngine/mperf

ã€Dipoorletï¼šç¦»çº¿é‡åŒ–å·¥å…·ï¼Œå¯ä»¥å¯¹ç»™å®šæ ¡å‡†æ•°æ®é›†ä¸Šçš„ONNXæ¨¡å‹è¿›è¡Œç¦»çº¿é‡åŒ–ã€‚æ”¯æŒå¤šç§æ¿€æ´»æ ¡å‡†ç®—æ³•ï¼Œå¦‚Mseã€Minmaxã€Histç­‰ï¼›æ”¯æŒæƒé‡è½¬æ¢ä»¥è·å¾—æ›´å¥½çš„é‡åŒ–ç»“æœï¼Œå¦‚BiasCorrectionã€WeightEqualizationç­‰ï¼›æ”¯æŒæœ€æ–°çš„ç¦»çº¿å¾®è°ƒç®—æ³•ä»¥æé«˜é‡åŒ–æ€§èƒ½ï¼Œå¦‚Adaroundã€Brecqã€Qdropã€‚æ­¤å¤–ï¼ŒDipoorletèƒ½ç”Ÿæˆå¤šä¸ªå¹³å°æ‰€éœ€çš„é‡åŒ–å‚æ•°ï¼Œå¹¶æä¾›è¯¦ç»†çš„é‡åŒ–åˆ†æä»¥å¸®åŠ©ç”¨æˆ·è¯†åˆ«æ¨¡å‹é‡åŒ–ä¸­çš„å‡†ç¡®æ€§ç“¶é¢ˆã€‚å®‰è£…å’Œä½¿ç”¨éƒ½å¾ˆç®€å•ï¼Œç”¨æˆ·éœ€è¦å‡†å¤‡æ ¡å‡†æ•°æ®é›†ï¼Œå¹¶åœ¨Pytorchåˆ†å¸ƒå¼ç¯å¢ƒæˆ–é›†ç¾¤ç¯å¢ƒä¸­è¿è¡ŒDipoorletã€‘'Dipoorlet - Offline Quantization Tools for Deploy.' ModelTC GitHub: github.com/ModelTC/Dipoorlet

ã€Autodistillï¼šä¸€ç§åˆ©ç”¨åŸºç¡€æ¨¡å‹è®­ç»ƒç›‘ç£æ¨¡å‹çš„æ–¹æ³•ï¼Œå¯ä»¥åœ¨æ²¡æœ‰æ ‡ç­¾çš„å›¾åƒä¸Šè¿›è¡Œæ¨ç†ã€‚é€šè¿‡è‡ªåŠ¨è’¸é¦ï¼Œå¯ä»¥å®ç°ä»æ— æ ‡ç­¾å›¾åƒåˆ°åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œæ¨ç†çš„è‡ªå®šä¹‰æ¨¡å‹ï¼Œå®Œå…¨æ— éœ€äººå·¥å¹²é¢„ã€‚ç›®å‰ï¼Œè‡ªåŠ¨è’¸é¦æ”¯æŒç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ç­‰è§†è§‰ä»»åŠ¡ï¼Œæœªæ¥è¿˜å¯ä»¥æ‰©å±•åˆ°æ”¯æŒè¯­è¨€ç­‰å…¶ä»–æ¨¡å‹ã€‘'Autodistill - Images to inference with no labeling (use foundation models to train supervised models)' GitHub: github.com/autodistill/autodistill

ã€InfiniTensorï¼šæ·±åº¦å­¦ä¹ é¢†åŸŸçš„ç¼–è¯‘å™¨é›†åˆï¼Œæ—¨åœ¨ç¼©å°æ·±åº¦å­¦ä¹ åº”ç”¨ä¸åç«¯ç¡¬ä»¶ä¹‹é—´çš„é¸¿æ²Ÿï¼Œé€šè¿‡ä½¿ç”¨ç¼–è¯‘å™¨è¶…ä¼˜åŒ–æŠ€æœ¯ï¼Œå¯¹ç¥ç»ç½‘ç»œæ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œè·å¾—æ›´å¥½çš„æ€§èƒ½ã€‘â€™InfiniTensor' GitHub: github.com/InfiniTensor/InfiniTensor

ã€OpenVINOâ„¢ Plugins for OBS Studioï¼šé€‚ç”¨äºOBS Studioçš„OpenVINOâ„¢æ’ä»¶ï¼Œç›®å‰æä¾›ä»¥ä¸‹æ’ä»¶ï¼šæ™ºèƒ½å‰ªè£(æ£€æµ‹åœºæ™¯ä¸­çš„äººä½“/äººè„¸ï¼Œè‡ªåŠ¨è£å‰ª/å±…ä¸­/è°ƒæ•´å¤§å°ä»¥å›´ç»•æ„Ÿå…´è¶£çš„ä¸»ä½“)ã€èƒŒæ™¯éšè—(å°†å‰æ™¯ä¸­çš„äººä¸èƒŒæ™¯åˆ†ç¦»ï¼Œé€šè¿‡æ¨¡ç³Šã€é™æ€å›¾åƒæˆ–è™šæ‹Ÿç»¿å¹•(ç”¨äºç»¿å¹•é”®æ§)åˆ é™¤èƒŒæ™¯)ã€äººè„¸ç½‘æ ¼(ä½¿ç”¨OpenVINOå’ŒOpenCVæ‰§è¡ŒMediapipeçš„äººè„¸ç½‘æ ¼æµæ°´çº¿ï¼Œåœ¨ç»“æœå¸§ä¸Šå åŠ 468ä¸ªäººè„¸å…³é”®ç‚¹)ã€‘â€™OpenVINOâ„¢ Plugins for OBS Studio' by Intel GitHub: github.com/intel/openvino-plugins-for-obs-studio

ã€Mobile GPUå·¥ä½œåŸç†è§£æ(æ¼«ç”»ç‰ˆ)ã€‘
https://armkeil.blob.core.windows.net/developer/Files/pdf/graphics-and-multimedia/how-does-a-mobile-gpu-work.pdf

'å¤©æ±  NVIDIA TensorRT Hackathon 2023 â€”â€” ç”Ÿæˆå¼AIæ¨¡å‹ä¼˜åŒ–èµ› åˆèµ›ç¬¬ä¸‰åæ–¹æ¡ˆ' TRT2022 GitHub: github.com/TRT2022/ControlNet_TensorRT

ã€Useful Transformersï¼šTransformeræ¨¡å‹é«˜æ•ˆæ¨ç†åº“ï¼Œé‡ç‚¹æ˜¯åœ¨è¾¹ç¼˜è¿è¡Œæ¨ç†çš„ä½æˆæœ¬ã€ä½èƒ½è€—å¤„ç†å™¨ï¼Œtiny.en Whisperæ¨¡å‹ä»¥30å€çš„å®æ—¶é€Ÿåº¦è¿è¡Œè½¬å½•è¯­éŸ³ï¼Œæ¯”æœ€çŸ¥åçš„å®ç°å¿«2å€ã€‘â€™Useful Transformers - Efficient Inference of Transformer models' Useful Sensors Inc GitHub: github.com/usefulsensors/useful-transformers

ã€MITçš„â€œTinyMLè¯­é«˜æ•ˆæ·±åº¦å­¦ä¹ è®¡ç®—â€è¯¾ç¨‹ï¼Œæ¶µç›–äº†ã€æ¨¡å‹å‹ç¼©ã€å‰ªæã€é‡åŒ–ã€ç¥ç»æ¶æ„æœç´¢ã€åˆ†å¸ƒå¼è®­ç»ƒã€æ•°æ®/æ¨¡å‹å¹¶è¡Œã€æ¢¯åº¦å‹ç¼©ä»¥åŠè®¾å¤‡ç«¯å¾®è°ƒç­‰ä¸»é¢˜ã€‘ã€Š6.5940 TinyML and Efficient Deep Learning Computingã€‹
https://efficientml.ai/

é€šè¿‡å¹¿æ³›æ¯”è¾ƒç¥ç»ç½‘ç»œé‡åŒ–å’Œå‰ªæä¸¤ç§æŠ€æœ¯ï¼Œå¾—å‡ºé‡åŒ–é€šå¸¸ä¼˜äºå‰ªæï¼Œåº”ä½œä¸ºæ¨¡å‹å‹ç¼©çš„é¦–é€‰çš„ç»“è®ºï¼Œå¸®åŠ©æŒ‡å¯¼ç¥ç»ç½‘ç»œç¡¬ä»¶è®¾è®¡é€‰æ‹©æ›´åˆé€‚çš„å‹ç¼©æ–¹æ³•ã€‚
https://arxiv.org/abs/2307.02973
[LG]ã€ŠPruning vs Quantization: Which is Better?ã€‹A Kuzmin, M Nagel, M v Baalen, A Behboodi, T Blankevoort [Qualcomm AI Research] (2023)

### ã€ç”Ÿäº§ç¯å¢ƒå¤§è¯­è¨€æ¨¡å‹ä¼˜åŒ–ã€‘
- éƒ¨ç½²å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹(LLM)éœ€è¦åº”å¯¹è®¡ç®—å’Œå†…å­˜éœ€æ±‚ï¼Œå…³é”®æ˜¯æé«˜æ¨¡å‹åœ¨é•¿æ–‡æœ¬è¾“å…¥ä¸‹çš„è®¡ç®—å’Œå†…å­˜æ•ˆç‡ã€‚   
- é™ä½å‚æ•°ç²¾åº¦ï¼Œå¦‚8æ¯”ç‰¹æˆ–4æ¯”ç‰¹é‡åŒ–ï¼Œå¯ä»¥å‡å°‘å†…å­˜éœ€æ±‚ï¼Œä»…è½»å¾®å½±å“æ€§èƒ½ã€‚   
- Flash Attentionç®—æ³•å¯ä»¥çº¿æ€§æé«˜å†…å­˜åˆ©ç”¨ç‡ï¼Œå¹¶åŠ é€Ÿè®¡ç®—ï¼Œæ˜¯é»˜è®¤è‡ªæ³¨æ„åŠ›çš„æ›´é«˜æ•ˆæ›¿ä»£ã€‚   
- ç›¸å¯¹ä½ç½®Embeddingå¦‚ALiBiå’ŒRoPEå¯ä»¥æ›´å¥½å¤„ç†é•¿æ–‡æœ¬è¾“å…¥ï¼Œå¹¶æ”¯æŒé•¿åº¦å¤–æ¨ã€‚   
- å…³é”®å€¼cacheæœºåˆ¶å¯ä»¥é‡å¤ä½¿ç”¨å…ˆå‰è®¡ç®—ï¼Œå‡å°‘è®¡ç®—é‡ï¼Œå¯¹ä¼šè¯ç­‰ä»»åŠ¡å°¤å…¶é‡è¦ã€‚   
- MQAå’ŒGQAé€šè¿‡å…±äº«é”®å€¼æŠ•å½±æˆ–åˆ†ç»„ï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘cacheå†…å­˜éœ€æ±‚ã€‚   
- Falconã€PaLMã€LLAMAç­‰æ–°æ¨¡å‹è®¾è®¡éƒ½é‡‡ç”¨äº†è¿™äº›ä¼˜åŒ–æŠ€æœ¯ï¼Œä»¥æ”¯æŒé•¿æ–‡æœ¬åœºæ™¯ã€‚   
- æŒç»­ç ”ç©¶å·¥ä½œè‡´åŠ›äºè¿›ä¸€æ­¥æå‡å¤§æ¨¡å‹è®¡ç®—å’Œå†…å­˜æ•ˆç‡ï¼Œéƒ¨ç½²LLMä»é¢ä¸´æŒ‘æˆ˜ã€‚é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ¨¡å‹æ¶æ„ååˆ†å…³é”®ã€‚
https://huggingface.co/blog/optimize-llm

### ã€EETQï¼šé’ˆå¯¹transformeræ¨¡å‹çš„é‡åŒ–å·¥å…·ï¼Œä½¿ç”¨Flash-Attention V2ä¼˜åŒ–attentionçš„æ¨ç†æ€§èƒ½ï¼Œç®€å•æ˜“ç”¨ï¼Œåªéœ€ä¸€è¡Œä»£ç å³å¯é€‚é…æ‚¨çš„PyTorchæ¨¡å‹ã€‘â€™EETQ - Easy and Efficient Quantization for Transformers' NetEase-FuXi GitHub: github.com/NetEase-FuXi/EETQ 

æ¯ä¸ªå¼€å‘äººå‘˜éƒ½åº”è¯¥äº†è§£ GPU è®¡ç®—çš„çŸ¥è¯† 
https://codeconfessions.substack.com/p/gpu-computing

ã€Togetherå…¬å¸æ¨å‡ºå…¨æ–°é«˜æ•ˆå¤§æ¨¡å‹æ¨æ–­å¼•æ“â€”â€”Together Inference Engineã€‘
- ç»è¿‡å¤šæœˆä¼˜åŒ–ï¼ŒåŒæ—¶é›†æˆäº†FlashAttention-2ï¼ŒFlash-Decodingå’ŒMedusaç­‰æŠ€æœ¯ï¼Œåœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹ï¼Œå…¶æ¨ç†é€Ÿåº¦å¯æ¯”TGIæˆ–vLLMå¿«3å€ï¼Œæ¯”ç«å“Perplexityç­‰å¿«2å€ã€‚   
- ä½¿ç”¨å¼€æºçš„LLMPerfè¿›è¡Œæµ‹è¯•è¡¨æ˜ï¼ŒTogetherå¼•æ“åœ¨Llama-2-70Bæ¨¡å‹ä¸Šå¯å®ç°117ä¸ªè¯/ç§’çš„é€Ÿåº¦ï¼Œåœ¨Llama-2-13Bæ¨¡å‹ä¸Šè¾¾åˆ°171è¯/ç§’ã€‚æ­¤å¤–ï¼Œè¯¥å¼•æ“ä¸å½±å“æ¨¡å‹è´¨é‡ï¼Œä¸åŒç²¾åº¦æµ‹è¯•ç»“æœä¸HuggingFaceä¸€è‡´ã€‚   
- æ­¤å¤–ï¼ŒTogetherå¼•æ“æ–°å¢äº†å¼¹æ€§SERVERLESS Endpointï¼Œæ”¯æŒè¶…è¿‡100ä¸ªä¼˜è´¨æ¨¡å‹ã€‚ç”¨æˆ·å¯é€‰æ‹©DEDICATED Instanceæˆ–å¼¹æ€§éƒ¨ç½²ï¼ŒåŒæ—¶æ”¯æŒè‡ªåŠ¨æ‰©ç¼©å®¹ã€‚æ¨¡å‹åº“ä¸æ–­å¢æ·»ï¼Œç°å·²è¶…è¿‡100ä¸ªæ¨¡å‹ã€‚   
- é‰´äºæ€§èƒ½æå‡å¸¦æ¥çš„è®¡ç®—æ•ˆç‡ï¼ŒTogetherå°†Llama-2-70Bæ¨¡å‹ä¼˜ä»·ä¸‹è°ƒè‡³0.0009ç¾å…ƒ/1000å­—ï¼Œä¸ºç”¨æˆ·æä¾›æ›´ä½æˆæœ¬çš„é«˜æ€§èƒ½æœåŠ¡ã€‚è¿™å¯¹æ¨åŠ¨AIåœ¨å„è¡Œä¸šçš„åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚   
- TogetherInference Engineå®ç°äº†ç›®å‰æœ€é«˜æ•ˆçš„LLMæ¨ç†ï¼Œä¸ºAIå‘å±•æä¾›äº†å¼ºåŠ²åŠ©åŠ›ã€‚
ã€ŠAnnouncing Together Inference Engine â€“ the fastest inference availableã€‹
https://www.together.ai/blog/together-inference-engine-v1

æå‡ºä¸€ç§å†…å­˜é«˜æ•ˆçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡çŸ©é˜µåˆ†è§£å’Œé‡åŒ–æŠ€æœ¯ï¼Œå‡å°‘å†…å­˜å ç”¨ï¼Œå¹¶åœ¨é€‚åº”æ€§å’Œå‹ç¼©æ€§èƒ½ä¸Šä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
https://arxiv.org/abs/2311.12023
[CL]ã€ŠLQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuningã€‹H Guo, P Greengard, E P. Xing, Y Kim [CMU & Columbia University] (2023)

ã€xFasterTransformerï¼šåœ¨X86 CPUä¸Šä¸ºå¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†è¿›è¡Œé«˜åº¦ä¼˜åŒ–çš„è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒæµè¡Œçš„LLMæ¨¡å‹ï¼Œå¦‚ChatGPTã€ChatGPT-2ã€LLamaã€LLama2ç­‰ï¼Œä¸ºå•èŠ‚ç‚¹å’Œå¤šèŠ‚ç‚¹å¤šå¥—ç³»ç»Ÿæ¨ç†æä¾›é«˜æ€§èƒ½å®ç°ï¼Œæä¾›C++å’ŒPythonä¸¤ç§APIï¼Œè¦†ç›–äº†ä»é«˜çº§åˆ°ä½çº§çš„æ¥å£ï¼Œä½¿ç”¨æˆ·å®¹æ˜“å°†å…¶é›†æˆåˆ°è‡ªå·±çš„è§£å†³æ–¹æ¡ˆä¸­ã€‘â€™xFasterTransformer' by Intel Corporation GitHub: github.com/intel/xFasterTransformer

ã€ç”¨PyTorchåŠ å¿«ç”Ÿæˆå¼AIï¼šå°†LLaMa 7Bæ€§èƒ½æå‡10å€ã€‘
- ä½¿ç”¨torch.compileå‡å°‘CPUå¼€é”€ï¼Œå°†æ›´å¤šå·¥ä½œé‡ä¸€æ¬¡æ€§é€å…¥GPUã€‚   
- ä½¿ç”¨int8é‡åŒ–ç¼©å°æƒé‡å¤§å°ï¼Œå‡è½»å†…å­˜å¸¦å®½å‹åŠ›ã€‚torch.compileå¯è‡ªåŠ¨ç”Ÿæˆå¯†é›†çš„int8é‡åŒ–æ ¸ã€‚   
- ä½¿ç”¨æ¨ç†è§£ç (speculative decoding)ï¼Œä½¿ç”¨å°æ¨¡å‹é¢„æµ‹å¤§æ¨¡å‹çš„è¾“å‡ºï¼Œå¯æ‰“ç ´åºåˆ—ä¾èµ–ã€‚   
- ä½¿ç”¨int4é‡åŒ–è¿›ä¸€æ­¥ç¼©å°æƒé‡å¤§å°ï¼Œå¯ä½¿ç”¨GPTQé‡åŒ–ç­–ç•¥æé«˜å‡†ç¡®ç‡ã€‚   
- ç»“åˆtorch.compileã€é‡åŒ–ã€æ¨ç†è§£ç ç­‰æŠ€æœ¯ï¼Œå¯å°†æ€§èƒ½æå‡10å€å·¦å³ã€‚   
- ä½¿ç”¨å¹¶è¡ŒæŠ€æœ¯ï¼Œåˆ†é…å·¥ä½œåˆ°å¤šä¸ªGPUï¼Œå¯è¿›ä¸€æ­¥å‡å°‘å»¶è¿Ÿï¼Œæ˜“äºåœ¨PyTorchä¸­å®ç°ã€‚   
- ä»¥ä¸Šä¼˜åŒ–æŠ€æœ¯å¯ä»¥å¾ˆå¥½åœ°ç»„åˆä½¿ç”¨ï¼Œæ‰€æœ‰ä¼˜åŒ–ä»…éœ€ä¸åˆ°1000è¡ŒPyTorchä»£ç ã€‚   
- PyTorchæä¾›äº†å¼ºå¤§çš„å·¥å…·æ¥åŠ é€Ÿç”Ÿæˆå¼æ¨¡å‹ï¼Œä¿æŒç®€å•æ€§ã€æ˜“ç”¨æ€§å’Œçµæ´»æ€§ã€‚
ã€ŠAccelerating Generative AI with PyTorch II: GPT, Fast | PyTorchã€‹
https://pytorch.org/blog/accelerating-generative-ai-2/

unslothï¼šè®©AIè®­ç»ƒå’Œå¾®è°ƒæœ€é«˜æé€Ÿ30å€
åœ°å€ï¼šgithub.com/unslothai/unsloth
å•†ä¸šå…¬å¸çš„äº§å“ï¼Œå¼€æºç‰ˆåªæ”¯æŒå•GPUï¼Œ2x faster ï¼Œ40% less memory â€‹â€‹â€‹

ã€unslothï¼šæ—¨åœ¨æä¾›2å€é€Ÿåº¦å’Œ50%å†…å­˜å ç”¨çš„è¯­è¨€æ¨¡å‹(LLM)å¾®è°ƒï¼Œæ”¯æŒæœ¬åœ° QLoRA å¾®è°ƒã€‘'unsloth - 2x faster 50% less memory LLM finetuning' GitHub: github.com/unslothai/unsloth

ã€ç”¨ç¨€ç–åŒ–å¾®è°ƒå’ŒDeepSparseåœ¨CPUä¸Šéƒ¨ç½²Llama 2ã€‘
- å±•ç¤ºäº†å¦‚ä½•é€šè¿‡åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­åº”ç”¨å‰ªæå’Œé‡åŒ–æ¥å‹ç¼©Llama 2æ¨¡å‹ï¼Œæ— æŸå‡†ç¡®ç‡ã€‚   
- é‡‡ç”¨INT8é‡åŒ–å’Œ60%ç¨€ç–åŒ–åï¼Œç²¾åº¦ä¸å˜ã€‚   
- DeepSparseå¯ä»¥åŠ é€Ÿç¨€ç–åŒ–é‡åŒ–çš„Llama 2æ¨¡å‹æ¨ç†ï¼Œåœ¨60-80%ç¨€ç–åŒ–ä¸‹æ¯”åŸºå‡†å¿«6-8å€ã€‚   
- è¯¦ç»†ä»‹ç»äº†å®ç°Llama 2çš„æƒé‡å’Œæ¿€æ´»é‡åŒ–çš„æŠ€æœ¯ã€‚   
- è¿™äº›æŠ€æœ¯å·²ç»åœ¨SparseMLå¼€æºåº“ä¸­å®ç°ï¼Œå¯ä¾›ä¼ä¸šæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆä½¿ç”¨ã€‚   
- ä¸‹ä¸€æ­¥å°†è¿›ä¸€æ­¥æå‡ç¨€ç–åŒ–ç‡ï¼Œæ‰©å±•æ¨¡å‹æ”¯æŒï¼Œå¹¶äº§å“åŒ–ç¨€ç–åŒ–å¾®è°ƒã€‚   
- è¯¥æ–¹æ³•å¯æœ‰æ•ˆå®ç°Llama 2åœ¨CPUé«˜æ€§èƒ½éƒ¨ç½²ï¼Œä¸ºGenAIåº”ç”¨æä¾›æ”¯æŒã€‚
ã€ŠFast Llama 2 on CPUs With Sparse Fine-Tuning and DeepSparse - Neural Magicã€‹
https://neuralmagic.com/blog/fast-llama-2-on-cpus-with-sparse-fine-tuning-and-deepsparse/